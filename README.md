# ğŸš€ TP Hadoop â€“ WordCount avec Docker

Ce README explique **toute lâ€™installation** du cluster Hadoop sous Docker, la configuration, la compilation du programme Java WordCount, le dÃ©ploiement dans Hadoop, lâ€™exÃ©cution du job MapReduce, la crÃ©ation du dossier `/data` dans HDFS, et la lecture des rÃ©sultats.

Ce guide reproduit exactement lâ€™environnement utilisÃ© dans le projet.

---

# ğŸ“¦ 1. PrÃ©-requis

* Docker installÃ©
* Docker Compose installÃ©
* Java installÃ© sur le **conteneur dev** (on lâ€™installera aprÃ¨s)
* Un dossier local contenant :

  * `docker-compose.yml` (cluster Hadoop)
  * `docker-compose.dev.yml` (conteneur Dev Ubuntu)
  * Un dossier `wordcount/` avec vos fichiers Java

Arborescence recommandÃ©e :

```
hadoop/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ hadoop.env
â”œâ”€â”€ file.txt (optionnel)
â””â”€â”€ wordcount/
    â”œâ”€â”€ WCDriver.java
    â”œâ”€â”€ WCMapper.java
    â””â”€â”€ WCReducer.java
```

---

# ğŸ³ 2. Lancer le cluster Hadoop

Placez-vous dans le dossier contenant `docker-compose.yml`.

```bash
cd /Users/.../hadoop
```

DÃ©marrer le cluster :

```bash
docker compose up -d
```

Les services suivants seront lancÃ©s :

* namenode
* datanode1 / datanode2 / datanode3
* resourcemanager
* nodemanager
* historyserver

Vous pouvez vÃ©rifier :

```bash
docker ps
```

---

# ğŸ–¥ï¸ 3. Lancer le conteneur Dev pour compiler WordCount

Le conteneur Dev est une Ubuntu utilisÃ©e pour compiler votre code Java.

DÃ©marrer le conteneur Dev :

```bash
docker compose -f docker-compose.dev.yml up -d
```

Entrer dans le conteneur :

```bash
docker exec -it hadoop-dev bash
```

Vous arriverez dans :

```
root@xxxx:/workspace
```

Ce dossier `/workspace` est automatiquement liÃ© au dossier `wordcount/` sur votre machine.

---

# â˜• 4. Installer Java dans le conteneur Dev

Dans le conteneur Dev :

```bash
apt update
apt install -y openjdk-11-jdk
```

VÃ©rifier :

```
javac -version
```

---

# ğŸ“ 5. DÃ©poser les fichiers WordCount dans le conteneur Hadoop (namenode)

Les fichiers `.java` sont sur votre machine, dans `wordcount/`.

Copiez-les dans le namenode :

```bash
docker cp wordcount namenode:/root/
```

Puis entrez dans le namenode :

```bash
docker exec -it namenode bash
```

VÃ©rifiez :

```bash
ls -la /root/wordcount
```

Vous devez voir :

```
WCDriver.java
WCMapper.java
WCReducer.java
```

---

# ğŸ§± 6. Compilation du WordCount dans le Namenode

Toujours dans `/root/wordcount` :

```bash
cd /root/wordcount
```

Compiler avec le classpath Hadoop :

```bash
javac -cp "$(hadoop classpath)" -d . wordcount/*.java
```

Si tout est correct, vous obtiendrez :

```
wordcount/WCDriver.class
wordcount/WCMapper.class
wordcount/WCReducer.class
```

---

# ğŸ“¦ 7. CrÃ©ation du JAR WordCount

Toujours dans `/root/wordcount` :

```bash
jar -cvf wc.jar wordcount
```

Votre JAR est maintenant prÃªt pour Hadoop.

---

# ğŸ“‚ 8. PrÃ©parer le dossier dâ€™entrÃ©e HDFS `/data`

CrÃ©er le dossier `/data` dans HDFS :

```bash
hdfs dfs -mkdir /data
```

CrÃ©er un fichier texte dâ€™entrÃ©e dans le namenode :

```bash
echo "hello hadoop world this is a big test hello hello" > /root/file.txt
```

Envoyer ce fichier dans HDFS :

```bash
hdfs dfs -put /root/file.txt /data
```

VÃ©rifier :

```bash
hdfs dfs -ls /data
```

---

# ğŸš€ 9. ExÃ©cuter le WordCount sur Hadoop

Dans le namenode :

```bash
hadoop jar wc.jar wordcount.WCDriver /data /output
```

Vous verrez Hadoop lancer :

* un job Map
* un job Reduce
* avec statistiques

Si tout se passe bien :

```
Job completed successfully
```

---

# ğŸ“– 10. Lire le rÃ©sultat du WordCount

Lire le fichier de sortie dans HDFS :

```bash
hdfs dfs -cat /output/part-r-00000
```

Exemple :

```
a       1
big     1
hadoop  1
hello   3
is      1
test    1
this    1
world   1
```

---

# ğŸ§¹ 11. Nettoyage (optionnel)

Supprimer un dossier HDFS :

```bash
hdfs dfs -rm -r /output
```

ArrÃªter tous les conteneurs Docker :

```bash
docker compose down
```

ArrÃªter aussi le Dev :

```bash
docker compose -f docker-compose.dev.yml down
```

---

# ğŸ‰ FIN â€” Votre WordCount Hadoop fonctionne !

Vous avez :

* un vrai cluster Hadoop
* un programme MapReduce Java compilÃ©
* un JAR exÃ©cutable
* un fichier dâ€™entrÃ©e dans HDFS
* une exÃ©cution complÃ¨te MapReduce
* un rÃ©sultat final affichÃ© depuis HDFS

Vous avez entiÃ¨rement validÃ© le TP Hadoop WordCount.

Vous pouvez maintenant passer tranquillement au TP2 ou Spark ğŸ˜ğŸ”¥

---

# ğŸ¤– Script d'automatisation : `compile_and_run.sh`

Un script `compile_and_run.sh` est fourni pour automatiser toutes les Ã©tapes dÃ©crites ci-dessus (compilation, crÃ©ation du JAR, exÃ©cution du job Hadoop).

## Utilisation

ExÃ©cutez simplement le script depuis votre terminal :

```bash
./compile_and_run.sh [options] [fichier_entree]
```

### Arguments Positionnels

*   `fichier_entree`: Chemin vers le fichier d'entrÃ©e local.
    *   **DÃ©faut** : `./src/wordcount/file.txt`

### Options

*   `-container=<nom>`: Nom du conteneur Docker oÃ¹ exÃ©cuter les commandes.
    *   **DÃ©faut** : `namenode`
*   `-jarName=<nom>`: Nom du fichier `.jar` Ã  crÃ©er.
    *   **DÃ©faut** : `wc.jar`
*   `-mainClass=<classe>`: Classe Java principale Ã  exÃ©cuter.
    *   **DÃ©faut** : `src.wordcountenseignant.WCDriver`
*   `-h, --help`: Affiche le message d'aide.

## Exemple

Pour lancer le WordCount sur un fichier diffÃ©rent avec la classe enseignante :

```bash
./compile_and_run.sh -mainClass=src.wordcountenseignant.WCDriver ./mon_fichier.txt
```
