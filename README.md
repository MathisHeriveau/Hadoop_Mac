# ğŸš€ TP Hadoop â€” WordCount avec Docker

Setup complet + ExÃ©cution MapReduce sous Hadoop 3.x

Ce projet installe un **cluster Hadoop complet**, compile automatiquement un **WordCount en Java**, lâ€™envoie dans le **namenode**, crÃ©e lâ€™input dans **HDFS**, exÃ©cute le job, et lit le rÃ©sultat.

Vous avez deux modes :
- **INSTALLATION AUTOMATIQUE**
- **INSTALLATION MANUELLE**


---

# âš¡ï¸ INSTALLATION AUTOMATIQUE (RECOMMANDÃ‰E)

Deux scripts :
- `./install.sh` â†’ installe et lance Hadoop + Dev + Java + copie WordCount
- `./wordcount/run_wordcount.sh` â†’ compile + jar + HDFS + exÃ©cution WordCount

## 1) Installation complÃ¨te

```bash
chmod +x install.sh
./install.sh
```

## 2) Lancer WordCount automatiquement

```bash
cd wordcount
chmod +x run_wordcount.sh
./run_wordcount.sh
```

---

# ğŸ§± INSTALLATION MANUELLE

## 1) PrÃ©-requis

- Docker + Docker Compose
- Structure :
```
hadoop/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.dev.yml
â”œâ”€â”€ wordcount/
â”‚   â”œâ”€â”€ WCDriver.java
â”‚   â”œâ”€â”€ WCMapper.java
â”‚   â”œâ”€â”€ WCReducer.java
â”‚   â””â”€â”€ file.txt
```

---

## 2) Lancer Hadoop

```bash
docker compose up -d
```

---

## 3) Lancer le conteneur Dev

```bash
docker compose -f docker-compose.dev.yml up -d
docker exec -it hadoop-dev bash
```

---

## 4) Installer Java dans Dev

```bash
apt update
apt install -y openjdk-11-jdk
javac -version
```

---

## 5) Copier WordCount dans le namenode

```bash
docker cp wordcount namenode:/root/
docker exec -it namenode bash
ls /root/wordcount
```

---

## 6) Compiler WordCount

```bash
cd /root/wordcount
javac -cp "$(hadoop classpath)" -d . wordcount/*.java
```

---

## 7) CrÃ©er le JAR

```bash
jar -cvf wc.jar wordcount
```

---

## 8) PrÃ©parer HDFS

```bash
hdfs dfs -mkdir -p /data
hdfs dfs -put -f /root/file.txt /data
```

---

## 9) ExÃ©cuter WordCount

```bash
hadoop jar wc.jar wordcount.WCDriver /data /output
```

---

## 10) Lire le rÃ©sultat

```bash
hdfs dfs -cat /output/part-r-00000
```

---

# ğŸ‰ FIN â€” Votre WordCount Hadoop fonctionne !

Vous avez :

* un vrai cluster Hadoop
* un programme MapReduce Java compilÃ©
* un JAR exÃ©cutable
* un fichier dâ€™entrÃ©e dans HDFS
* une exÃ©cution complÃ¨te MapReduce
* un rÃ©sultat final affichÃ© depuis HDFS

Vous avez entiÃ¨rement validÃ© le TP Hadoop WordCount.

Vous pouvez maintenant passer tranquillement au TP2 ou Spark ğŸ˜ğŸ”¥

---

# ğŸ¤– Script d'automatisation : `compile_and_run.sh`

Un script `compile_and_run.sh` est fourni pour automatiser toutes les Ã©tapes dÃ©crites ci-dessus (compilation, crÃ©ation du JAR, exÃ©cution du job Hadoop).

## Utilisation

ExÃ©cutez simplement le script depuis votre terminal :

```bash
./compile_and_run.sh [options] [fichier_entree]
```

### Arguments Positionnels

*   `fichier_entree`: Chemin vers le fichier d'entrÃ©e local.
    *   **DÃ©faut** : `./src/wordcount/file.txt`

### Options

*   `-container=<nom>`: Nom du conteneur Docker oÃ¹ exÃ©cuter les commandes.
    *   **DÃ©faut** : `namenode`
*   `-jarName=<nom>`: Nom du fichier `.jar` Ã  crÃ©er.
    *   **DÃ©faut** : `wc.jar`
*   `-mainClass=<classe>`: Classe Java principale Ã  exÃ©cuter.
    *   **DÃ©faut** : `src.wordcountenseignant.WCDriver`
*   `-h, --help`: Affiche le message d'aide.

## Exemple

Pour lancer le WordCount sur un fichier diffÃ©rent avec la classe enseignante :

```bash
./compile_and_run.sh -mainClass=src.wordcountenseignant.WCDriver ./mon_fichier.txt
```
